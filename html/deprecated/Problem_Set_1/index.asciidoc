---
tags: []
title: Problem_Set_1
---
*Deadline: Mon 9/27, 7:00pm*

For this problem set, you should do the below:

* Install one or both of the below:
** Acrobat Pro, *do not distribute these licenses, for CS50 use this
semester only*
*** http://www.cs50.net/forstaffonly/GH34245/MacAdobePro.dmg[Mac OS],
activate with s/n 1118-0004-6698-3847-9152-9356
***
http://www.cs50.net/forstaffonly/GH34245/Adobe_Acrobat_Pro_Win_v93.iso[Windows],
activate with s/n 1118-1000-1694-3105-7694-0760
** Bluebeam PDF Revu Standard Edition v 8, *do not distribute this
license, for CS50 use this semester only*
*** http://www.bluebeam.com/standard[Windows], activate with s/n
1042911, product key VFWY9-L58E7AA
* link:#_fetching_submissions_and_making_pdfs[Fetch your students' code
and make PDFs] thereof.
* Open the Google Spreadsheet called *cs50/2010/pset1/username* (which
should have been shared with your @gmail.com account), make a copy via
*File â†’ Make a copy...*, and change *username* in the copy to your own
cloud username.
* Repeat for *cs50/2010/hacker1/username* if any of your students
tackled Hacker Edition (which you'll know if you have any directories in
`both1` named `username.hacker1`).
* Use your copy of the spreadsheet to determine a student's Correctness
score (out of 5), which should auto-compute in the green row. *Use
Mike's link:#_grading_scripts[grading scripts] to automate the
calculation of correctness scores to the extent possible.* Manual
evaluation might be necessary if, e.g., student's code doesn't compile.
(If getting code to compile requires just a few tweaks on your part, do
so in order to see which tests their code then passes.)
* Decide on a Design and Style score for each student too using your
judgement. Most/many students should get 1's for Design; odds are
there's room for improvement in one or more places in each program. Push
them toward writing better code next time. As for Style, code that
simply isn't commented (or is barely) probably warrants a 0; most
students should probably get 2 or 1. Bear in mind that the specs said
"Be sure that your code is thoroughly commented to such an extent that
lines' functionality is apparent from comments alone." The amount of
comments you see in lectures' source code is a good guide for reasonable
expectations.
* Provide qualitative feedback in the form of an email to each student
or, ideally, by marking up the PDF of their code. Feel free to summarize
their Correctness, Design, and Style scores in the PDF, but focus your
time on qualitative feedback. Where can they improve? Which lines should
be elsewhere? Draw lines or text boxes as you see fit.
* Access your students' form submissions at
https://www.cs50.net/tools/wufoo/pset1.php[https://www.cs50.net/tools/wufoo/pset1.php].
* Record each student's Correctness, Design, and Style score in your
gradebook at http://www.cs50.net/tools/[cs50.net/tools].
* Email each student their PDF, mention they can view their Correctness,
Design, and Style scores at
http://www.cs50.net/grades/[cs50.net/grades], and comment (if briefly)
on their answers to the survey's RAM questions. (No points are allocated
to the RAM questions this time; do not deduct from discretionary.) _Do
not disclose the point-by-point breakdown of students' Correctness
score._ We want their focus to remain on the big picture.
* Hang on to the PDFs too; we'll eventually upload them to the cloud for
archival.

[[]]
Fetching Submissions and Making PDFs
------------------------------------

The `fetch` and `render` scripts live in `~cs50/staff/bin`. The former
unpacks submission tarballs, storing the unpacked directories in a
directory that you designate. The latter uses the unpacked submission
subdirectories to create PDFs of source code for grading. Here's a
typical example of how `fetch` and `render` are used:

---------------------------------
export PATH=~cs50/staff/bin:$PATH
mkdir both1
fetch pset1 both1
fetch hacker1 both1
render pset1 both1/*.pset1
render hacker1 both1/*.hacker1
---------------------------------

The commands above assume that the user is a TF, and they process all of
the students in her section. If John Harvard is one of those who
submitted the hacker edition, then the result will be a subdirectory
`both1/jharvard.hacker1` containing his code and a file
`both1/jharvard.pdf` listing the important source files in it. (There is
also a tiny file `both1/jharvard.timestamp` that passes the submission
time from `fetch` to `render`.)

The `fetch` and `render` scripts have options for handling special
cases. You can fetch the submissions for another TF by using the `-t`
option of `fetch`. Or you can fetch submissions by individual student
name using one or more instances of the `-u` option. When `render`ing,
you can customize the set of source files to collect, and you can also
fiddle with the information printed on the cover sheet. To read about
all of the options, run `fetch` or `render` without any arguments.

[[]]
Grading Scripts
---------------

The provided grading scripts should give you a rough estimate of a
student's score for the correctness portion (unless they exactly copied
our output perfectly, in which case tthe grading is quite easy).
Depending on whether you are grading a hacker assignment or not you will
run the appropriate command on the cloud from inside a students
directory (e.g. from inside `both1/jharvard.hacker1`:

--------------------------------------------------
~mtucker/personal/scripts/trunk/ps1-scripts/ps1.pl
--------------------------------------------------

or

------------------------------------------------------
~mtucker/personal/scripts/trunk/ps1-scripts/hacker1.pl
------------------------------------------------------

Running this command will give you a flurry of output that contains the
rough estimate mentioned above and will also create a test_output
directory with more information. If something went Horribly Wrong(tm)
with the student's code, you may see messages like Floating Point
Exception mixed in with our score printouts.

Each of these scripts mentioned above will in turn run its own scripts
(e.g. `check-chart.pl` or `check-hacker-chart.pl`), which each try a few
test cases on the student's binary and will compare them to our solution
set. The script will create a test_output directory in your local
directory where it will put the output from the student's binary and a
few summary files named per binary.

The files in test_output called *-score.txt attempts to distill the
tests down to a number for each of the rows in David's Google
spreadsheet. In places where that wasn't possible, the script should say
so.

If you want to look at the inputs for the test cases or otherwise fiddle
with the internals of the test system, you can look (but please don't
change) the files in ~mtucker/personal/scripts/trunk/ps1-scripts or
direct questions to mtucker@eecs.harvard.edu.

[[]]
standard edition
----------------

[[]]
hello.c
~~~~~~~

It's okay if a student didn't actually submit `hello.c`, since it was
just a warm-up exercise.

[[]]
Correctness
^^^^^^^^^^^

Not scored.

[[]]
Design
^^^^^^

Not scored.

[[]]
Style
^^^^^

Not scored. Comment on PDF only if applicable.

[[]]
skittles.c
~~~~~~~~~~

[[]]
Correctness
^^^^^^^^^^^

See Google Spreadsheet.

[[]]
Design
^^^^^^

Did they use a looping construct in the "right" way? Some students might
have implemented a function besides main. That's fine but was it
necessary? Perhaps pose the question.

[[]]
Style
^^^^^

Program should have at least a few comments. Variables should be aptly
named.

[[]]
greedy.c
~~~~~~~~

[[]]
Correctness
^^^^^^^^^^^

See Google Spreadsheet.

[[]]
Design
^^^^^^

Though it involves a bit of copy/paste, having four, back-to-back loops
is okay, I think, for such a short program. Using a function or array in
some fashion is probably fine too. Could the student have implemented
the program more cleanly?

[[]]
Style
^^^^^

Program should have at least a few comments. Variables should be aptly
named.

[[]]
chart.c
~~~~~~~

[[]]
Correctness
^^^^^^^^^^^

See Google Spreadsheet.

[[]]
Design
^^^^^^

Is program's design pretty clean? Unnecessarily complicated?

[[]]
Style
^^^^^

[[]]
Hacker Edition
--------------

[[]]
hello.c
~~~~~~~

It's okay if a student didn't actually submit `hello.c`, since it was
just a warm-up exercise.

[[]]
Correctness
^^^^^^^^^^^

Not scored.

[[]]
Design
^^^^^^

Not scored.

[[]]
Style
^^^^^

Not scored. Comment on PDF only if applicable.

[[]]
skittles.c
~~~~~~~~~~

See link:#_standard_edition[standard edition].

[[]]
credit.c
~~~~~~~~

[[]]
Correctness
^^^^^^^^^^^

See Google Spreadsheet.

[[]]
Design
^^^^^^

Clean? Overly complicated?

[[]]
Style
^^^^^

Program should have at least a few comments. Variables should be aptly
named.

[[]]
chart.c
~~~~~~~

See link:#_standard_edition[standard edition], though remember that
Hacker Edition mandates vertical bars.
