---
tags: []
title: Sort_algorithms
---
__FORCETOC__

[[]]
Bubble Sort
-----------

Bubble sort gets its name from the way that values "bubble up" to the
end of the array while it is being sorted. The basic concept is simple:
iterate over the elements in the array comparing them to each other two
at a time; if two elements are out of order with respect to each other
(i.e. the larger value is closer to the beginning of the array in the
case that we are sorting the array from least to greatest), then swap
them.

Consider the following unsorted array and pay attention to the number 8
as we traverse the array once:

8 2 5 6 7 1 4 3 +
2 8 5 6 7 1 4 3 +
2 5 8 6 7 1 4 3 +
2 5 6 8 7 1 4 3 +
2 5 6 7 8 1 4 3 +
2 5 6 7 1 8 4 3 +
2 5 6 7 1 4 8 3 +
2 5 6 7 1 4 3 8 +
 By the end of this first traversal of the array, the number 8 is in its
correct position.

To sort the remainder of the array, we'll need to traverse it another 7
times. On each traversal, another number will end up in its correct
position.

On each successive traversal of the array, we can stop one more element
short of the end. After the first traversal, for example, we already
know that the 8 is in place at the end of the list, so we can stop at
the 7th position. On the next traversal, we can stop at the 6th
position. And so on.

Given this, we can deduce that for a generalized array of
latexmath:[$n$] elements, we must make latexmath:[$n$] traversals of the
array, the first traversal taking latexmath:[$n$] steps, the second
traversal taking latexmath:[$n$]−1 steps, and so on. If you add all
these up, you'll get slightly less than latexmath:[$n^2$] steps in
total, but we will count it as latexmath:[$n^2$]. Thus, bubble Sort is
in latexmath:[$O(n^2)$].

What about the best-case scenario? If the array is already sorted, we
still need to traverse it once in order to verify that it is sorted. How
do we know it is sorted? If no swaps are made during a traversal, then
we know the array is already sorted. Thus, if we keep track of the
number of swaps that are made, bubble sort is in
latexmath:[$\Omega(n^2)$].

[[]]
Insertion Sort
--------------

Insertion sort is very similar to selection sort. Like bubble sort and
selection sort, it is in latexmath:[$O(n^2)$]. Whereas in selection
sort, after latexmath:[$k$] traversals of the array, the first
latexmath:[$k$] elements of the array will be the smallest elements in
the array, in insertion sort, the first latexmath:[$k$] elements will be
the original latexmath:[$k$] elements in the unsorted array, but now in
sorted order. Consider the following example:

5 7 0 3 4 2 6 1

0 5 7 3 4 2 6 1

0 3 5 7 4 2 6 1

0 3 4 5 7 2 6 1

0 2 3 4 5 7 6 1

0 2 3 4 5 6 7 1

0 1 2 3 4 5 6 7

On the k^th^ traversal of the array, we walk to the k^th^ element of the
array and swap it with its neighbors to the left until it doesn't need
to be swapped anymore.

In the best case (the array is already sorted), this algorithm runs in
linear time (latexmath:[$\Omega(n)$]).

[[]]
Selection Sort
--------------

Selection Sort is another sort algorithm in latexmath:[$O(n^2)$]. In the
worst case, we must traverse the array latexmath:[$n$]−1 times. On the
first traversal of the array, we pick the smallest number in the array
and swap it into the first position. On the second traversal, we start
from the second element of the array (since we already know that the
first number in the array is in the correct position) and again pick the
smallest number, this time swapping it into the second position. The
last traversal of the array starts from the second-to-last element in
the array and takes only one step: swapping the last two elements if
necessary. We don't need the _n_^th^ traversal because we know the last
element in the list is in the correct position based on our previous
work. However, because we consider only the highest-degree term in
determining link:big O notation[big O notation], selection sort still
runs in latexmath:[$O(n^2)$].

If you're thinking that we could optimize selection sort by pulling the
smallest number out of the array and shifting the other numbers to the
right, think again. Whereas a swap requires only one step, this shifting
of numbers would require multiple steps on each traversal of the array
and would be much more expensive.

In the best-case scenario, selection sort still takes latexmath:[$n^2$]
steps because the computer has no way of knowing on any iteration
through the array that the smallest number is already in the correct
position.

[[]]
Merge Sort
----------

Merge Sort, just like link:binary search[binary search], improves upon
other algorithms by taking the divide-and-conquer approach: by cutting
the problem in half multiple times, we end up with a more manageable
problem. Unlike all the other sort algorithms we consider in CS50, merge
sort is in latexmath:[$O(n\log n)$].

Let’s begin by examining a pseudocode implementation of merge sort:

---------------------------------
On input of n elements: 
If n < 2 
    Return. 
Else 
    Sort left half of elements. 
    Sort right half of elements. 
    Merge sorted halves. 
---------------------------------

When we say “Sort left half,” what we really mean is to start this
entire algorithm over using a list of half the original size. You can
think of all of the lines of pseudocode above as belonging to a function
called `Sort` which calls itself if it is passed 2 or more elements. The
fact that this algorithm calls itself is what makes it recursive.

The latexmath:[$n$]\<2 is the base case of this recursive algorithm. To
prevent it from looping inﬁnitely, we check if there are fewer than 2
elements in the list. If latexmath:[$n$]\<2, then there is only a single
item in the list and, as we said before, a single item considered by
itself is already sorted.

Consider the following array: 4, 2, 6, 8, 1, 3, 7, 5. Using merge sort,
we’re going to recursively chop it in half until we’re left with two
lists of size one: 4 and 2. Each of these lists is already “sorted,” so
now we need to merge them. How do we merge? Well, 2 is less than 4, so
we want to put the 2 list before the 4 list. Where will we store these?
In reality, we’re going to need more memory to store the sorted total
list.

Now that 2 and 4 are in order, we step back for a second. 2 and 4
comprise the left half of a list of four: 4, 2, 6, 8. So now that we’ve
sorted the left half of this list, we need to sort the right half,
namely 6, 8. Again, we divide this list of length two into two lists of
length one: 6 and 8. Then, we merge them, putting 6 before 8.

One of the key takeaways to keep in mind with this algorithm is that
we’re only looking at each number once. Because it makes fewer
comparisons than bubble sort or selection sort, merge sort is much
faster.

Now, again we’re at the merging step. The left half is 2, 4 and the
right half is 6, 8. Let’s point our left hand at the ﬁrst element of the
left half and our right hand at the ﬁrst element of the right half. 2 is
less than 6, so we put 2 in ﬁrst. Now we’ll advance our left hand one
step so that it’s pointing at 4. Our right hand is still pointing at 6
because we haven’t merged that number yet. We compare 4 and 6 and then
put 4 into our sorted array. Then we put 6 and 8 in because there’s
nothing to compare them against.

At this point, we’ve completed the very step in our ﬁrst call to merge
sort: we’ve sorted the left half of the entire original list. Now we’ll
sort the right half: 1, 3, 7, 5.

Cutting out a few of the intermediate steps, we end up with two sorted
lists of size two: 1, 3 and 5, 7. When we merge them we end up with 1,
3, 5, 7. Finally, we’ll merge this right half with the original left
half, 2, 4, 6, 8. Obviously, we’ll end up with 1, 2, 3, 4, 5, 6, 7, 8.
We’ll do so by iterating over both lists comparing the current left
number to the current right number, selecting the smaller, and advancing
to the next number in the list we just took a number from.
